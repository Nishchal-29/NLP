{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9166b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import text_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58584185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csharp', 'python', 'javascript', 'java']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = '/home/devcontainers/Datasets/train'\n",
    "test_dir = '/home/devcontainers/Datasets/test'\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "016ed5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"blank - install modules from source i downloaded a repo from github and installed it in a virtualenv using $blank setup.py install in the project dir...this works fine. now, when i open a file and induce an error, (like changing return to lol) it still installs fine. what is going on ? i wished to assert that my changes do not break the module and was hoping to install each time i make a change.\"\n",
      "\n",
      "\"how do i run an executable, then continue after it stops? what i'm wanting to do is save files written by the executable i'm running to a dropbox folder. the files are saved at random times, so i can't use a timer...the only ways i know of executing files are non-blocking, and when i run the functions, they simply just execute and continue (for example, using subprocess to run a start command with the argument being the executable)...i can't modify the executable, i can only run it...here's what i've tried so far: i have looked up the question and haven't found anything. the only way i know of executing something with blank is using the  suprocess' call function and the popen function, and using the start command to execute the executable. but that is still non-blocking, and continues after the executable has started, not ended.\"\n",
      "\n",
      "\"how to determine if first two elements of a value are integers or characters? my task is save the number of a day in a value..for example:..today_str = 10-2-2018..date_numb = 10...or:..today_str = 3/5/2018..date_numb = 3...to sum up, i wanna check if its 2 integers or 1 so i can save the day's number in a value.\"\n",
      "\n",
      "\"blank : convert between 0-> 500 and x -> y i'm trying to convert a number x between [0;500] into [x;y] in blank...thanks, sydney.\"\n",
      "\n",
      "\"convert and process a dictionary to matrix in blank i have a big list in blank like the following small example:..small example:..['gaattccttgaggcctaaatgcatcggggtgctctggttttgttgttgttatttctgaatgacatttactttggtgctctttattttgcgtatttaaaac', 'taagtccctaagcatatatataatcatgagtagttgtggggaaaataacaccattaaatgtaccaaaacaaaagaccgatcacaaacactgccgatgtttctctggcttaaattaaatgtatatacaacttatatgataaaatactgggc']...i want to make a new list in which every string will be converted to a new list and every list has some tuples. in fact i want to divide the length of each string by 10. the 1st tuple would be (1, 10) and the 2nd tuple would be (10, 20) until the end , depending on the length of the string. at the end, every string will be a list oftuples and finally i would have a list of lists..in the small example the 1st string has 100 characters and the 2nd string has 150 characters. .for example the expected output for the small example would be:..new_list = [[(1, 10), (10, 20), (20, 30), (30, 40), (40, 50), (50, 60), (60, 70), (70, 80), (80, 90), (90, 100)],  [(1, 10), (10, 20), (20, 30), (30, 40), (40, 50), (50, 60), (60, 70), (70, 80), (80, 90), (90, 100), (100, 110), (110, 120), (120, 130), (130, 140), (140, 150)]]...to make such list i made the following code but it does not return what i expect. do you know how to fix it?..mylist = [].valtup = list().for count, char in enumerate(mylist):.    if count % 10 == 0 and count &gt; 0:.        valtup.append(count).    else:.        new_list.append(tuple(valtup))\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So, we have 4 classes. Let's see what we have inside python class\n",
    "\n",
    "python_dir = os.path.join(train_dir, 'python')\n",
    "python_txt = os.listdir(python_dir)\n",
    "python_txt = python_txt[:5]\n",
    "for txt in python_txt:\n",
    "    with open(os.path.join(python_dir, txt), 'r') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99ff20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparameters\n",
    "\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "maxLen = 300\n",
    "vocab_size = 10000\n",
    "embedding_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d79793ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n",
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n",
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds_raw = text_dataset_from_directory(train_dir, batch_size=batch_size, validation_split=0.2, subset='training', seed=seed, label_mode='categorical')\n",
    "val_ds_raw = text_dataset_from_directory(train_dir, batch_size=batch_size, validation_split=0.2, subset='validation', seed=seed, label_mode='categorical')\n",
    "test_ds_raw = text_dataset_from_directory(test_dir, batch_size=batch_size, label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97e10c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the text contains html tags and punctuation which are not much needed to build our vocabulary, so we will remove them\n",
    "\n",
    "def standardize_texts(data):\n",
    "    lowercase = tf.strings.lower(data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(standardize=standardize_texts, max_tokens=vocab_size, output_mode='int', output_sequence_length=maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a53b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vectorization layer using texts from the training set \n",
    "train_texts = train_ds_raw.map(lambda x, y : x)\n",
    "vectorize_layer.adapt(train_texts)\n",
    "\n",
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "# Applying the vectorization layer to each text in dataset\n",
    "train_ds = train_ds_raw.map(vectorize_text)\n",
    "val_ds = val_ds_raw.map(vectorize_text)\n",
    "test_ds = test_ds_raw.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b2e25ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "user\n",
      "taking\n",
      "essential\n"
     ]
    }
   ],
   "source": [
    "print(vectorize_layer.get_vocabulary()[9])\n",
    "print(vectorize_layer.get_vocabulary()[99])\n",
    "print(vectorize_layer.get_vocabulary()[999])\n",
    "print(vectorize_layer.get_vocabulary()[9999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e452f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01e9565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape=(maxLen,))\n",
    "emb = layers.Embedding(vocab_size, embedding_dim)(input)\n",
    "x = layers.Dropout(0.2)(emb)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "output = layers.Dense(4, activation='softmax')(x)\n",
    "model = tf.keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83413b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │       \u001b[38;5;34m500,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m13,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514,084</span> (1.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m514,084\u001b[0m (1.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">514,084</span> (1.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m514,084\u001b[0m (1.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a989b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 19:17:02.239342: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_835', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - categorical_accuracy: 0.2878 - loss: 1.3801\n",
      "Epoch 1: val_loss improved from inf to 1.25539, saving model to text_classifier_stack_overflow.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - categorical_accuracy: 0.2886 - loss: 1.3795 - val_categorical_accuracy: 0.3919 - val_loss: 1.2554\n",
      "Epoch 2/10\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.4689 - loss: 1.1874\n",
      "Epoch 2: val_loss improved from 1.25539 to 0.99912, saving model to text_classifier_stack_overflow.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - categorical_accuracy: 0.4698 - loss: 1.1858 - val_categorical_accuracy: 0.5294 - val_loss: 0.9991\n",
      "Epoch 3/10\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.6054 - loss: 0.9169\n",
      "Epoch 3: val_loss improved from 0.99912 to 0.83476, saving model to text_classifier_stack_overflow.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - categorical_accuracy: 0.6062 - loss: 0.9156 - val_categorical_accuracy: 0.6269 - val_loss: 0.8348\n",
      "Epoch 4/10\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.6900 - loss: 0.7603\n",
      "Epoch 4: val_loss improved from 0.83476 to 0.79109, saving model to text_classifier_stack_overflow.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - categorical_accuracy: 0.6901 - loss: 0.7600 - val_categorical_accuracy: 0.6612 - val_loss: 0.7911\n",
      "Epoch 5/10\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.7271 - loss: 0.6715\n",
      "Epoch 5: val_loss improved from 0.79109 to 0.72878, saving model to text_classifier_stack_overflow.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - categorical_accuracy: 0.7273 - loss: 0.6712 - val_categorical_accuracy: 0.6931 - val_loss: 0.7288\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.7554 - loss: 0.6094\n",
      "Epoch 6: val_loss did not improve from 0.72878\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - categorical_accuracy: 0.7555 - loss: 0.6093 - val_categorical_accuracy: 0.6963 - val_loss: 0.7511\n",
      "Epoch 7/10\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.7814 - loss: 0.5580\n",
      "Epoch 7: val_loss improved from 0.72878 to 0.61963, saving model to text_classifier_stack_overflow.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - categorical_accuracy: 0.7816 - loss: 0.5575 - val_categorical_accuracy: 0.7462 - val_loss: 0.6196\n",
      "Epoch 8/10\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.8132 - loss: 0.4902\n",
      "Epoch 8: val_loss did not improve from 0.61963\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - categorical_accuracy: 0.8134 - loss: 0.4897 - val_categorical_accuracy: 0.7525 - val_loss: 0.6328\n",
      "Epoch 9/10\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - categorical_accuracy: 0.8292 - loss: 0.4527\n",
      "Epoch 9: val_loss improved from 0.61963 to 0.58766, saving model to text_classifier_stack_overflow.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - categorical_accuracy: 0.8295 - loss: 0.4521 - val_categorical_accuracy: 0.7725 - val_loss: 0.5877\n",
      "Epoch 10/10\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - categorical_accuracy: 0.8462 - loss: 0.4029\n",
      "Epoch 10: val_loss did not improve from 0.58766\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - categorical_accuracy: 0.8466 - loss: 0.4020 - val_categorical_accuracy: 0.7744 - val_loss: 0.6046\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.metrics.CategoricalAccuracy()])\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('text_classifier_stack_overflow.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "history = model.fit(train_ds, batch_size=batch_size, epochs=10, validation_data=val_ds, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6b7a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - categorical_accuracy: 0.7452 - loss: 0.6723\n",
      "0.6696485280990601\n",
      "0.7484999895095825\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ac1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
